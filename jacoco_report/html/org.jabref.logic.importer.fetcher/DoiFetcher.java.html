<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="fr"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>DoiFetcher.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">JabRef</a> &gt; <a href="index.source.html" class="el_package">org.jabref.logic.importer.fetcher</a> &gt; <span class="el_source">DoiFetcher.java</span></div><h1>DoiFetcher.java</h1><pre class="source lang-java linenums">package org.jabref.logic.importer.fetcher;

import java.io.IOException;
import java.net.HttpURLConnection;
import java.net.URL;
import java.net.URLConnection;
import java.util.Collections;
import java.util.List;
import java.util.Optional;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.CompletionException;
import java.util.regex.Pattern;

import org.jabref.logic.cleanup.FieldFormatterCleanup;
import org.jabref.logic.formatter.bibtexfields.ClearFormatter;
import org.jabref.logic.formatter.bibtexfields.NormalizePagesFormatter;
import org.jabref.logic.help.HelpFile;
import org.jabref.logic.importer.EntryBasedFetcher;
import org.jabref.logic.importer.FetcherException;
import org.jabref.logic.importer.IdBasedFetcher;
import org.jabref.logic.importer.ImportFormatPreferences;
import org.jabref.logic.importer.ParseException;
import org.jabref.logic.importer.fileformat.BibtexParser;
import org.jabref.logic.importer.util.MediaTypes;
import org.jabref.logic.l10n.Localization;
import org.jabref.logic.net.URLDownload;
import org.jabref.model.entry.BibEntry;
import org.jabref.model.entry.field.StandardField;
import org.jabref.model.entry.identifier.DOI;
import org.jabref.model.entry.types.StandardEntryType;
import org.jabref.model.util.OptionalUtil;

import com.google.common.util.concurrent.RateLimiter;
import kong.unirest.json.JSONArray;
import kong.unirest.json.JSONException;
import kong.unirest.json.JSONObject;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class DoiFetcher implements IdBasedFetcher, EntryBasedFetcher {

    public static final String NAME = &quot;DOI&quot;;

    private static final String APS_JOURNAL_ORG_DOI_ID = &quot;1103&quot;;
    private static final String APS_SUFFIX = &quot;([\\w]+\\.)([\\w]+\\.)([\\w]+)&quot;;
<span class="fc" id="L46">    private static final Pattern APS_SUFFIX_PATTERN = Pattern.compile(APS_SUFFIX);</span>

<span class="fc" id="L48">    private static final Logger LOGGER = LoggerFactory.getLogger(DoiFetcher.class);</span>

    // 1000 request per 5 minutes. See https://support.datacite.org/docs/is-there-a-rate-limit-for-making-requests-against-the-datacite-apis
<span class="fc" id="L51">    private static final RateLimiter DATA_CITE_DCN_RATE_LIMITER = RateLimiter.create(3.33);</span>

    /*
     * By default, it seems that CrossRef DOI Content Negotiation responses are returned by their API pools, more specifically the public one
     * (by default). See https://www.crossref.org/documentation/retrieve-metadata/content-negotiation/
     * Experimentally, the rating applied to this pool is defined by response headers &quot;X-Rate-Limit-Interval&quot; and &quot;X-Rate-Limit-Limit&quot;, which seems
     * to default to 50 request / second. However, because of its dynamic nature, this rate could change between API calls, so we need to update it
     * atomically when that happens (as multiple threads might access it at the same time)
     */
<span class="fc" id="L60">    private static final RateLimiter CROSSREF_DCN_RATE_LIMITER = RateLimiter.create(50.0);</span>

    private final ImportFormatPreferences preferences;

<span class="fc" id="L64">    public DoiFetcher(ImportFormatPreferences preferences) {</span>
<span class="fc" id="L65">        this.preferences = preferences;</span>
<span class="fc" id="L66">    }</span>

    @Override
    public String getName() {
<span class="fc" id="L70">        return DoiFetcher.NAME;</span>
    }

    @Override
    public Optional&lt;HelpFile&gt; getHelpPage() {
<span class="nc" id="L75">        return Optional.of(HelpFile.FETCHER_DOI);</span>
    }

    private void doAPILimiting(String identifier) {
        // Without a generic API Rate Limiter implemented on the project, use Guava's RateLimiter for avoiding
        // API throttling when multiple threads are working, specially during DOI Content Negotiations
<span class="fc" id="L81">        Optional&lt;DOI&gt; doi = DOI.parse(identifier);</span>

        try {
            Optional&lt;String&gt; agency;
<span class="pc bpc" id="L85" title="2 of 4 branches missed.">            if (doi.isPresent() &amp;&amp; (agency = getAgency(doi.get())).isPresent()) {</span>
<span class="fc" id="L86">                double waitingTime = 0.0;</span>
<span class="fc bfc" id="L87" title="All 2 branches covered.">                if (&quot;datacite&quot;.equalsIgnoreCase(agency.get())) {</span>
<span class="fc" id="L88">                    waitingTime = DATA_CITE_DCN_RATE_LIMITER.acquire();</span>
<span class="fc bfc" id="L89" title="All 2 branches covered.">                } else if (&quot;crossref&quot;.equalsIgnoreCase(agency.get())) {</span>
<span class="fc" id="L90">                    waitingTime = CROSSREF_DCN_RATE_LIMITER.acquire();</span>
                } // mEDRA does not explicit an API rating

<span class="fc" id="L93">                LOGGER.trace(&quot;Thread %s, searching for DOI '%s', waited %.2fs because of API rate limiter&quot;.formatted(</span>
<span class="fc" id="L94">                        Thread.currentThread().threadId(), identifier, waitingTime));</span>
            }
<span class="nc" id="L96">        } catch (IOException e) {</span>
<span class="nc" id="L97">            LOGGER.warn(&quot;Could not limit DOI API access rate&quot;, e);</span>
<span class="fc" id="L98">        }</span>
<span class="fc" id="L99">    }</span>

    protected CompletableFuture&lt;Optional&lt;BibEntry&gt;&gt; asyncPerformSearchById(String identifier) {
<span class="fc" id="L102">        doAPILimiting(identifier);</span>
<span class="fc" id="L103">        return CompletableFuture.supplyAsync(() -&gt; {</span>
            try {
<span class="fc" id="L105">                return performSearchById(identifier);</span>
<span class="fc" id="L106">            } catch (FetcherException e) {</span>
<span class="fc" id="L107">                throw new CompletionException(e);</span>
            }
        });
    }

    @Override
    public Optional&lt;BibEntry&gt; performSearchById(String identifier) throws FetcherException {
<span class="fc" id="L114">        Optional&lt;DOI&gt; doi = DOI.parse(identifier);</span>

        try {
<span class="fc bfc" id="L117" title="All 2 branches covered.">            if (doi.isPresent()) {</span>
                Optional&lt;BibEntry&gt; fetchedEntry;

                // mEDRA does not return a parsable bibtex string
<span class="fc" id="L121">                Optional&lt;String&gt; agency = getAgency(doi.get());</span>
<span class="pc bpc" id="L122" title="1 of 4 branches missed.">                if (agency.isPresent() &amp;&amp; &quot;medra&quot;.equalsIgnoreCase(agency.get())) {</span>
<span class="fc" id="L123">                    return new Medra().performSearchById(identifier);</span>
                }
<span class="fc" id="L125">                URL doiURL = new URL(doi.get().getURIAsASCIIString());</span>

                // BibTeX data
<span class="fc" id="L128">                URLDownload download = getUrlDownload(doiURL);</span>
<span class="fc" id="L129">                download.addHeader(&quot;Accept&quot;, MediaTypes.APPLICATION_BIBTEX);</span>

                String bibtexString;
                URLConnection openConnection;
                try {
<span class="fc" id="L134">                    openConnection = download.openConnection();</span>
<span class="fc" id="L135">                    bibtexString = URLDownload.asString(openConnection).trim();</span>
<span class="fc" id="L136">                } catch (IOException e) {</span>
                    // an IOException with a nested FetcherException will be thrown when you encounter a 400x or 500x http status code
<span class="pc bpc" id="L138" title="1 of 2 branches missed.">                    if (e.getCause() instanceof FetcherException fe) {</span>
<span class="fc" id="L139">                        throw fe;</span>
                    }
<span class="nc" id="L141">                    throw e;</span>
<span class="fc" id="L142">                }</span>

                // BibTeX entry
<span class="fc" id="L145">                fetchedEntry = BibtexParser.singleFromString(bibtexString, preferences);</span>
<span class="fc" id="L146">                fetchedEntry.ifPresent(this::doPostCleanup);</span>

                // Crossref has a dynamic API rate limit
<span class="pc bpc" id="L149" title="1 of 4 branches missed.">                if (agency.isPresent() &amp;&amp; &quot;crossref&quot;.equalsIgnoreCase(agency.get())) {</span>
<span class="fc" id="L150">                    updateCrossrefAPIRate(openConnection);</span>
                }

                // Check if the entry is an APS journal and add the article id as the page count if page field is missing
<span class="pc bpc" id="L154" title="2 of 4 branches missed.">                if (fetchedEntry.isPresent() &amp;&amp; fetchedEntry.get().hasField(StandardField.DOI)) {</span>
<span class="fc" id="L155">                    BibEntry entry = fetchedEntry.get();</span>
<span class="pc bpc" id="L156" title="1 of 4 branches missed.">                    if (isAPSJournal(entry, entry.getField(StandardField.DOI).get()) &amp;&amp; !entry.hasField(StandardField.PAGES)) {</span>
<span class="fc" id="L157">                        setPageCountToArticleId(entry, entry.getField(StandardField.DOI).get());</span>
                    }
                }

<span class="pc bpc" id="L161" title="1 of 2 branches missed.">                if (openConnection instanceof HttpURLConnection connection) {</span>
<span class="fc" id="L162">                    connection.disconnect();</span>
                }
<span class="fc" id="L164">                return fetchedEntry;</span>
            } else {
<span class="fc" id="L166">                throw new FetcherException(Localization.lang(&quot;Invalid DOI: '%0'.&quot;, identifier));</span>
            }
<span class="nc" id="L168">        } catch (IOException e) {</span>
<span class="nc" id="L169">            throw new FetcherException(Localization.lang(&quot;Connection error&quot;), e);</span>
<span class="nc" id="L170">        } catch (ParseException e) {</span>
<span class="nc" id="L171">            throw new FetcherException(&quot;Could not parse BibTeX entry&quot;, e);</span>
<span class="nc" id="L172">        } catch (JSONException e) {</span>
<span class="nc" id="L173">            throw new FetcherException(&quot;Could not retrieve Registration Agency&quot;, e);</span>
        }
    }

    private void doPostCleanup(BibEntry entry) {
<span class="fc" id="L178">        new FieldFormatterCleanup(StandardField.PAGES, new NormalizePagesFormatter()).cleanup(entry);</span>
<span class="fc" id="L179">        new FieldFormatterCleanup(StandardField.URL, new ClearFormatter()).cleanup(entry);</span>
<span class="fc" id="L180">    }</span>

    private void updateCrossrefAPIRate(URLConnection existingConnection) {
        try {
            // Assuming this field is given in seconds
<span class="fc" id="L185">            String xRateLimitInterval = existingConnection.getHeaderField(&quot;X-Rate-Limit-Interval&quot;).replaceAll(&quot;[^\\.0123456789]&quot;, &quot;&quot;);</span>
<span class="fc" id="L186">            String xRateLimit = existingConnection.getHeaderField(&quot;X-Rate-Limit-Limit&quot;);</span>

<span class="fc" id="L188">            double newRate = Double.parseDouble(xRateLimit) / Double.parseDouble(xRateLimitInterval);</span>
<span class="fc" id="L189">            double oldRate = CROSSREF_DCN_RATE_LIMITER.getRate();</span>

            // In theory, the actual update might rarely happen...
<span class="pc bpc" id="L192" title="1 of 2 branches missed.">            if (Math.abs(newRate - oldRate) &gt;= 1.0) {</span>
<span class="nc" id="L193">                LOGGER.info(&quot;Updated Crossref API rate limit from %.2f to %.2f&quot;.formatted(oldRate, newRate));</span>
<span class="nc" id="L194">                CROSSREF_DCN_RATE_LIMITER.setRate(newRate);</span>
            }
<span class="nc" id="L196">        } catch (NullPointerException | IllegalArgumentException e) {</span>
<span class="nc" id="L197">            LOGGER.warn(&quot;Could not deduce Crossref API's rate limit from response header. API might have changed&quot;);</span>
<span class="fc" id="L198">        }</span>
<span class="fc" id="L199">    }</span>

    @Override
    public List&lt;BibEntry&gt; performSearch(BibEntry entry) throws FetcherException {
<span class="nc" id="L203">        Optional&lt;String&gt; doi = entry.getField(StandardField.DOI);</span>
<span class="nc bnc" id="L204" title="All 2 branches missed.">        if (doi.isPresent()) {</span>
<span class="nc" id="L205">            return OptionalUtil.toList(performSearchById(doi.get()));</span>
        } else {
<span class="nc" id="L207">            return Collections.emptyList();</span>
        }
    }

    /**
     * Returns registration agency. Optional.empty() if no agency is found.
     *
     * @param doi the DOI to be searched
     */
    public Optional&lt;String&gt; getAgency(DOI doi) throws IOException {
<span class="fc" id="L217">        Optional&lt;String&gt; agency = Optional.empty();</span>
        try {
<span class="fc" id="L219">            URLDownload download = getUrlDownload(new URL(DOI.AGENCY_RESOLVER + &quot;/&quot; + doi.getDOI()));</span>
<span class="fc" id="L220">            JSONObject response = new JSONArray(download.asString()).getJSONObject(0);</span>
<span class="pc bpc" id="L221" title="1 of 2 branches missed.">            if (response != null) {</span>
<span class="fc" id="L222">                agency = Optional.ofNullable(response.optString(&quot;RA&quot;));</span>
            }
<span class="nc" id="L224">        } catch (JSONException e) {</span>
<span class="nc" id="L225">            LOGGER.error(&quot;Cannot parse agency fetcher response to JSON&quot;);</span>
<span class="nc" id="L226">            return Optional.empty();</span>
<span class="fc" id="L227">        }</span>

<span class="fc" id="L229">        return agency;</span>
    }

    private void setPageCountToArticleId(BibEntry entry, String doiAsString) {
<span class="fc" id="L233">        String articleId = doiAsString.substring(doiAsString.lastIndexOf('.') + 1);</span>
<span class="fc" id="L234">        entry.setField(StandardField.PAGES, articleId);</span>
<span class="fc" id="L235">    }</span>

    // checks if the entry is an APS journal by comparing the organization id and the suffix format
    private boolean isAPSJournal(BibEntry entry, String doiAsString) {
<span class="fc bfc" id="L239" title="All 2 branches covered.">        if (!entry.getType().equals(StandardEntryType.Article)) {</span>
<span class="fc" id="L240">            return false;</span>
        }
<span class="fc" id="L242">        String suffix = doiAsString.substring(doiAsString.lastIndexOf('/') + 1);</span>
<span class="fc" id="L243">        String organizationId = doiAsString.substring(doiAsString.indexOf('.') + 1, doiAsString.indexOf('/'));</span>
<span class="pc bpc" id="L244" title="1 of 4 branches missed.">        return organizationId.equals(APS_JOURNAL_ORG_DOI_ID) &amp;&amp; APS_SUFFIX_PATTERN.matcher(suffix).matches();</span>
    }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.10.202304240956</span></div></body></html>